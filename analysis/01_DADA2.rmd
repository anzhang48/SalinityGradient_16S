---
title: "Infer ASVs with DADA2"
author: "Andy Zhang"
output: html_document
date: "2024-02-21"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "../figures/01_DADA2/")
```
# Before you start

## Set my seed
```{r set-seed}
# Any number can be chosen
set.seed(895820392)

```
# Goals of this file

1.  Use row fastq files and generate quality plots to assess quiality of reads.
2.  Filter out and trim out bad sequences and bases from our sequencing files.
3.  Write out fastq files with high quality sequences
4.  Evaluate the quality from our filter and trim

# Load Libraries

```{r load-libraies}
#install.packages("devtools")
library(devtools)

#devtools::install_github("benjjneb/dada2")

#install.packages("tidyverse")
library(tidyverse)

#install.packages("patchwork")
library(patchwork)
```

# Load Data

```{r load-data}
# Set Raw fastq path to the raw sequencing files
# Path to the fastq files
raw_fastq_path <- "data/01_DADA2/01_raw_gzippedfastqs"
raw_fastq_path

# What files are in this path? Intuition Check
list.files(raw_fastq_path)

# How many files are there?
str(list.files(raw_fastq_path))

# Create vector of forward reads
raw_forward_reads <- list.files(raw_fastq_path, pattern = "R1_001.fastq.gz", full.names = TRUE)
head(forward_reads)
str(forward_reads)

# Create a vector of reverse reads
raw_reverse_reads <- list.files(raw_fastq_path, pattern = "R2_001.fastq.gz", full.names = TRUE)
# Intution Check
head(reverse_reads)
```

# Quality Plots

```{r raw-quality-plot}
# Randomly Select two samples to evaluate
random_samples <- sample(1:length(reverse_reads), size = 2)
random_samples

# Calculate and plot quality of these two samples
plotQualityProfile(raw_forward_reads[random_samples]+
                     labs(title = "Raw Forward Quality Plot"))
plotQualityProfile(raw_reverse_reads[random_samples]+
                     labs(title = "Raw Reverse Quality Plot"))

```

# Prepare a place holder for filtered reads

```{r prep-filtered-sequences}
# Vector of our samples, extract sample name from files
samples <- sapply(strsplit(basename(forward_reads), "_"), '[',1)
# Intuition Check
head(samples)
  
# Place filtered reads into filtered_fastq_path
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# Create 2 variables: filtered_F, filtered_R
filtered_forward_reads <- 
  file.path(filtered_fastqs_path, paste0(samples, "_R1_filtered.fastq.gz"))
length(filtered_forward_reads)
head(filtered_forward_reads)

# Same thing for reverse reads
filtered_reverse_reads <- 
  file.path(filtered_fastqs_path, paste0(samples, "_R2_filtered.fastq.gz"))
length(filtered_reverse_reads)
head(filtered_reverse_reads)
```

# Filter and Trim Reads

Parameters of filter and trim **DEPEND ON THE DATASET**

- 'maxN' = number of N bases. Remove all Ns from the data.
- 'maxEE' = Quality Filtering threshold, applied to expected error. Here, if there's 2 expected errors. It's ok. But more than 2. Thrown away the sequence. Two values, first is for the forward reads; second is for reverse reads.
- 'trimleft' Number of nucleotides to remove at the start of each read.
- 'truncQ' Truncate reads after truncLen bases. Reads shorter than this are discarded.

```{r filter-and-trim}
# Assign vector to filtered reads
# trim out poor bases, first 3 bps on F reads
# write out filtered fastq files
filtered_reads <- filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads,
              rev = reverse_reads, filt.rev = filtered_reverse_reads,
              maxN = 0, maxEE = c(2,2), trimLeft = 3,
              truncQ = 2, rm.phix = TRUE, compress = TRUE)
# Intuition Check
length(filtered_reads)
```

# Graphing Filter and Trim Quality Plots

```{r filter-trim-quality-plot}



```

# Aggregated Trimmed Plots
```{r}
# Aggregate QC Plots
#install and library patchwork
plotQualityProfile(filtered_forward_reads, aggregate = TRUE) +
  plotQualityProfile(filtered_reverse_reads, aggregate = TRUE)

```

## Stats on read output from "filterAndTrim"

```{r FilterTrim-stats}
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)

# Statistics on our Reads
filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_percent_retained = (median(reads.out/median(reads.in))))
```

#Error Modeling

**Note** Run separately on each Illumina dataset.
```{r learn-errors}

# Forward Reads
error_forward_reads <- 
  learnErrors(filtered_forward_reads) 
#multithreaded = TRUE"

# Reverse Reads
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads) 
#multithreaded = TRUE"

# Plot reverse
plotErrors(error_reverse_reads, nominalQ = TRUE)+
  labs(title = "Reverse Read Error Model")
```

# Infer ASVs

Note this is happening seperately on the forward and reverse reads. This is unique to DADA2.

```{r Infer ASVs}
#Infer forward ASVs
dada_forward <- dada(filtered_forward_reads,
                     err = error_forward_reads)
                     #multithread = TRUE
#Infer reverse ASVs
dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads)
                     #multithread = TRUE

```

```{r Graph ASVs}


```
# Session Information

```{r session-info}
# Ensure reproducibility
devtools::session_info()
```